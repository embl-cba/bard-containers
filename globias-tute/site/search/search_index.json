{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A brief introduction to HPC clusters and SLURM","text":"<p>This hands-on session is designed to run on BAND, a virtual desktop platform for bioimage analysis.  </p> <p>It is aimed at people getting started with SLURM cluster.  </p> <p>We will use the EuBI-Bridge package to convert images to OME-Zarr, as an example of running jobs on a SLURM cluster.</p> <p>\ud83d\udcd1 The presentation slides can be viewed at: Google Slides</p>"},{"location":"files_on_band/","title":"Files on BAND","text":"<ul> <li>Example image data: <code>/scratch/ngff_workshop/examples/</code> </li> <li>Conda environment: <code>/scratch/miniforge3/envs/eubizarr</code> </li> <li>SLURM binaries: <code>/opt/slurm-23.02.8/bin/</code></li> </ul>"},{"location":"login/","title":"Log in to BAND","text":"<ol> <li> <p>Go to one of the following:</p> <ul> <li>bandv1.denbi.uni-tuebinigen.de</li> <li>band.vm.fedcloud.eu</li> </ul> </li> <li> <p>Sign up with your Google account.</p> </li> <li>Once your account is ready, log in and launch a desktop with 2CPUs, 16G RAM, no GPU.</li> </ol> <p>Important: Do not use your first desktop.</p>"},{"location":"references/","title":"References","text":"<ul> <li>SLURM Documentation: https://slurm.schedmd.com/documentation.html</li> <li>EuBI-Bridge: https://github.com/Euro-BioImaging/EuBI-Bridge</li> <li>OME-Zarr paper: https://link.springer.com/article/10.1007/s00418-023-02209-1</li> <li>BAND platform: https://doi.org/10.5281/zenodo.12699364</li> </ul>"},{"location":"exercises/1_basic_slurm/","title":"Exercise 1: Basic SLURM Commands","text":"<p>In this exercise, we will practice the basic <code>sinfo</code>, <code>squeue</code>, <code>scontrol</code>, and <code>scancel</code> commands to interact with the job scheduler.</p> <p>Once you have a BAND desktop, start a terminal.</p> <p></p>"},{"location":"exercises/1_basic_slurm/#check-available-nodes","title":"Check available nodes","text":"<pre><code>sinfo\n</code></pre> <p>This shows cluster partitions, number of nodes, and their state.</p> <p></p>"},{"location":"exercises/1_basic_slurm/#common-states","title":"Common states","text":"<pre><code>idle  : ready for work\nalloc : node is fully allocated. no free resources.\nmix   : some resources are available, some are in use.\ndown  : unavailable\ndrain : unavailable\n</code></pre>"},{"location":"exercises/1_basic_slurm/#check-running-job","title":"Check running job","text":"<pre><code>squeue\n</code></pre> <p>Useful flags:</p> <pre><code>squeue -u $USER # only show your job\n</code></pre> <ul> <li><code>$USER</code> is a shell variable, which automatically expands to your login username</li> <li>You can also manually specifying a username string instead of relying on the variable, e.g.</li> </ul> <pre><code>squeue -u use-your-username\n</code></pre> <ul> <li>To find out your username:</li> </ul> <pre><code>whoami\n</code></pre> <p>\ud83d\udc49 You should see 1 job under your name, which is your running BAND desktop. Note the JobID.</p> <p></p> <ul> <li> <p>On the BAND platform, username is derived from your email in this way:</p> <ul> <li>Take everything before the <code>@</code></li> <li>Take the first token after <code>@</code> and before <code>.</code></li> <li>Concatenate them with an uderscore <code>_</code></li> </ul> </li> </ul> <p>For example:</p> <ul> <li>Email: <code>abcd@example.com</code></li> <li>Username: <code>abcd_example</code></li> </ul>"},{"location":"exercises/1_basic_slurm/#show-detailed-job-information","title":"Show detailed job information","text":"<pre><code>scontrol show job &lt;JobID&gt;\n</code></pre>"},{"location":"exercises/1_basic_slurm/#cancel-a-job","title":"Cancel a job","text":"<pre><code>scancel &lt;JoBID&gt;\n</code></pre>"},{"location":"exercises/1_basic_slurm/#task-try-canceling-your-own-desktop-job","title":"Task: Try canceling your own desktop job.","text":"<p>If successful:</p> <ul> <li> <p>You\u2019ll lose connection to your desktop (red connection error).</p> </li> <li> <p>Close the browser tab, return to the launch page \u2192 no desktop running.</p> </li> <li> <p>Launch another desktop and open a terminal again to continue.</p> </li> </ul> <p></p> <p>Note: If you cancel another person\u2019s job, you should get a permission denied error.</p> <p></p>"},{"location":"exercises/2_convert_local/","title":"Exercise 2: Convert Images Locally","text":"<p>In this exercise we will convert images locally on your BAND desktop. These steps do not use the cluster. The goal is to help you become familiar with the EuBI-Bridge image conversion tool before we use it in later exercises.</p>"},{"location":"exercises/2_convert_local/#activate-the-conda-environment","title":"Activate the conda environment:","text":"<pre><code>source /scratch/miniforge3/etc/profile.d/conda.sh      # source the conda binary\nconda activate eubizarr                                # activate the eubizarr environment\n</code></pre> <ul> <li>You could list all the available conda enviroments using <code>conda env list</code>.</li> <li>Always check you are using the correct conda environment. </li> </ul>"},{"location":"exercises/2_convert_local/#create-a-results-folder","title":"Create a results folder:","text":"<pre><code>mkdir ~/results_local                                              \n</code></pre> <ul> <li>The <code>~</code> expand to your own home folder, e.g. <code>/home/YOUSUSERNAME/</code></li> <li>On BAND, you only have write permission to your home folder and <code>/scratch</code></li> <li>You can create any folder under <code>~</code> or <code>/scratch</code> to store results.</li> </ul>"},{"location":"exercises/2_convert_local/#run-the-conversion","title":"Run the conversion","text":"<pre><code>eubi to_zarr /scratch/ngff_workshop/examples/pff ~/results_local   \n</code></pre> <ul> <li>These steps convert all images in the <code>pff</code> folder into Zarr format and save the results in <code>~/results_local</code>.</li> <li>The conversion only uses 1 node.</li> <li>The conversion runs on the same node where your BAND desktop is running.</li> </ul>"},{"location":"exercises/2_convert_local/#check-the-results","title":"Check the results","text":"<p>List the contents of the output folder:</p> <pre><code>ls ~/results_local\n</code></pre>"},{"location":"exercises/2_convert_local/#expected-output","title":"Expected output:","text":"<ul> <li>There should be 7 Zarr folders</li> </ul>"},{"location":"exercises/3_convert_slurm/","title":"Exercise 3: Parallel Image Conversion","text":"<p>In this exercise, we will run the image conversion using EuBI-Bridge's built-in parallelization features, and observe how it utilizes cluster.</p>"},{"location":"exercises/3_convert_slurm/#monitor-the-queue-in-a-second-terminal","title":"Monitor the queue in a second terminal","text":"<p>Open a second terminal and run:</p> <pre><code>watch -n 0.5 squeue -u YOUR_USERNAME\n</code></pre> <p>This updates <code>squeue</code> every 0.5s to monitor the queue.</p>"},{"location":"exercises/3_convert_slurm/#run-the-conversion","title":"Run the conversion","text":"<p>In your first terminal (with the conda environment activated), run:</p> <pre><code>mkdir ~/results_cluster             # make result folder\neubi to_zarr /scratch/ngff_workshop/examples/pff ~/results_cluster --on_slurm=True # run the conversion on slurm\n</code></pre>"},{"location":"exercises/3_convert_slurm/#what-happens","title":"What happens?","text":"<ul> <li>EuBI-Bridge uses Dask internally to submit jobs to SLURM.</li> <li><code>--on_slurm=True</code> enables EuBI-Bridge to submit jobs to SLURM.</li> <li>The jobs are sent to the default partition(<code>batch</code>).</li> <li>You should see 4 new jobs appear in the <code>squeue</code> output. </li> <li>The name of the jobs is <code>dask-worker</code>.  </li> </ul>"},{"location":"exercises/3_convert_slurm/#tips","title":"Tips:","text":"<ul> <li>By default, EuBI-Bridge starts 4 jobs.</li> <li>To request more jobs, check the EuBI-Bridge documentation for more configuration options.</li> <li>Always check the content of <code>~/results_cluster</code> to confirm the conversion finished. </li> <li>If you need to re-run the conversion command, remove the <code>~/results_cluster</code>:</li> </ul> <pre><code>rm -rf ~/results_cluster\n</code></pre>"},{"location":"exercises/4_sbatch/","title":"Exercise 4: Image Conversion with sbatch","text":"<p>Not all software supports internal parallelizationn so in this exercise, we will use SLURM's <code>sbatch</code> and job array to parallelize our image conversion tasks</p>"},{"location":"exercises/4_sbatch/#inspect-the-example-script","title":"Inspect the example script","text":"<p>An example script is available at:</p> <pre><code>/scratch/ngff_workshop/submit_job.sbatch\n</code></pre> <p>Read the comments in the file.</p>"},{"location":"exercises/4_sbatch/#submit-the-job","title":"Submit the job","text":"<p>Remember in Exercise 3, EuBI-Bridge by default start 4 jobs. Instead of changing the configs in EuBi-Bridge to have more jobs submitted, we can use sbatch to do the same with the SLURM's <code>--array</code> parameter.</p> <p>Make a copy of the <code>submit_job.sbatch</code> script to your own home folder</p> <pre><code>cp /scratch/ngff_workshop/submit_job.sbatch /home/YOUR_USERNAME\n</code></pre> <p>Submit it to SLURM</p> <pre><code>sbatch /home/YOUR_USERNAME/submit_job.sbatch (use your own path)\n</code></pre> <p>Expected output(example):</p> <pre><code>Submitted batch job 529\n</code></pre> <p>The number <code>529</code> is the job id. </p>"},{"location":"exercises/4_sbatch/#check-the-queue","title":"Check the queue","text":"<p>Open your monitoring terminal, you should see: </p> <p>The above screenshot tells you</p> <ul> <li>sbatch submitted 7 jobs for the conversion.</li> <li>2 out of the 7 jobs run at a time</li> <li>You can change this behaviour using SBATCH parameters in the .sbatch script.</li> </ul>"},{"location":"exercises/4_sbatch/#check-log-files","title":"Check log files","text":"<p>Output and error logs are stored in:</p> <pre><code>    ~/ngfflogs/ngffjob_&lt;job_id&gt;.out  # This is the stdout log \n    ~/ngfflogs/ngffjob_&lt;job_id&gt;.err  # This is the error log\n</code></pre>"},{"location":"exercises/4_sbatch/#verify-the-results","title":"Verify the results","text":"<p>Check the converted Zarr files:</p> <ul> <li>The are stored in folder <code>results_[0-6]</code> (<code>results_1, results_2 ... results_6</code>)</li> <li>Each folder contains 1 Zarr dataset.</li> </ul>"},{"location":"exercises/5_visualize/","title":"Exercise 5: Visualize Converted Zarr Files in Fiji","text":"<p>In this exercise, we will visualise the converted Zarr datasets using Fiji on BAND.</p>"},{"location":"exercises/5_visualize/#open-fiji","title":"Open Fiji","text":"<p>On your BAND desktop:</p> <ul> <li>Go to Applications \u2192 Image Analysis \u2192 Fiji</li> <li>It may take a while to start (~1min)</li> </ul>"},{"location":"exercises/5_visualize/#import-the-zarr-data","title":"Import the Zarr data","text":"<p>In Fiji:</p> <ol> <li>Select File \u2192 Import \u2192 HDF5/N5/Zarr/OME-NGFF </li> <li>Browse to the folder where your converted Zarr files are stored (<code>~/results_local</code>, <code>~/results_cluster</code>, or <code>results_[0-6]</code>).  </li> <li>Open one of the datasets.</li> </ol> <p></p> <p>Explore the data to confirm the conversion was successful.  </p> <p>Try comparing a locally converted Zarr vs. a cluster-converted Zarr.</p>"}]}